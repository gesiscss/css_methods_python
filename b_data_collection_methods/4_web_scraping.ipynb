{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26acf247",
   "metadata": {},
   "source": [
    "<img src='images/gesis.png' style='height: 60px; float: left'>\n",
    "<img src='images/social_comquant.png' style='height: 50px; float: left; margin-left: 40px'>\n",
    "<img src='images/isi.png' style='height: 50px; float: left; margin-left: 20px'>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c8be6",
   "metadata": {},
   "source": [
    "Authors = \n",
    "\n",
    "Date = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ddebc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_5135712360854264229() {\n",
       "                $('div.cell.code_cell.rendered.selected').find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            \n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_5135712360854264229()\">Toggle show/hide</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import random\n",
    "\n",
    "def hide_toggle(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Toggle show/hide'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' next cell'\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)\n",
    "\n",
    "hide_toggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd4ea4a",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "Data collection is a procedure of gathering information from subjects (all relevant sources), measuring and analyzing accurate insights for research using various techniques. Researchers can evaluate their research questions and hypotheses on the basis of collected data. In most cases, data collection is the primary and most important step for research, irrespective of the field of study. The approach of data collection varies for different fields of study, depending on the required information.\n",
    "\n",
    "The internet is an absolutely massive source of data which we can access by various ways such as connecting APIs (see Teaching Module 3.1. API harvesting). In addtion to APIs, web scraping is often the only way we can access data that it is not available in convenient CSV exports or APIs. Websites are often valuable sources of data; for example, weather forecasts, comments on news sites, and posts on forums. To access those sorts of information on webpages, we will use web scraping.\n",
    "\n",
    "With this online module, we are going to show how to do web scraping with Python from scratch. Then, we will work through an actual web scraping project, focusing on ??? data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66abdeec",
   "metadata": {},
   "source": [
    "# 2. Fundamentals of Web scarping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c403de1f",
   "metadata": {},
   "source": [
    "<img src=\"./images/webscrape.png\"  width=\"350\" height = \"350\" align=\"center\"/>\n",
    "\n",
    "In order to access APIs, you first need to create an account and apply to have a developer account on the platform that you want to work on. With this developer account, platforms provide you KEYS (e.g., secret, public, or access) to authenticate their system.\n",
    "\n",
    "While web scraping is one of the common ways of collecting data from websites, a lot of websites offer APIs to access the public data that they host on their website. This is to avoid unnecessary traffic on the websites.\n",
    "\n",
    "However, even though we have access to these API, as researchers, we should not forget to respect API access rules and always read the documents before collecting data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f0bacd",
   "metadata": {},
   "source": [
    "## 2.0 Feed Parsing [<a href='#destination1'>1, 2, 3</a>] <a id='destination1_'></a>\n",
    "\n",
    "According to [Wikipedia](https://en.wikipedia.org/wiki/Web_feed), a web feed (or news feed) is a data format used for providing users with frequently updated content. Content distributors syndicate a web feed, thereby allowing users to subscribe a channel to it by adding the feed resource address to a news aggregator client (also called a feed reader or a news reader). Users typically subscribe to a feed by manually entering the URL of a feed or clicking a link in a web browser or by dragging the link from the web browser to the aggregator, thus \"RSS and Atom files provide news updates from a website in a simple form for your computer.\"\n",
    "\n",
    "Here we introduce [feedparser](https://pypi.org/project/feedparser/), a powerful python package for parsing RSS feeds. By providing the RSS feed link, we can get structured information in the form of python lists and dictionaries, which could then be used to extract the desired information in a simple and efficient way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cac09b",
   "metadata": {},
   "source": [
    "### 2.0.1 Getting started with feedparser\n",
    "\n",
    "\n",
    "You can easily install the feedparser package using pip command:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8541458",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pip install feedparser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e145ad",
   "metadata": {},
   "source": [
    "As usual, we need to import the package in the first place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35773d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb80565f",
   "metadata": {},
   "source": [
    "#### Parsing an RSS feed URL\n",
    "To parse an RSS feed link, you can simply use the **parse()** method from the feedparser package. It takes a string as argument, which could be a URL or the address to the file locally saved on the computer. Here we use CNN RSS as an example URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23239687",
   "metadata": {},
   "outputs": [],
   "source": [
    "feed = feedparser.parse(\"https://www.voanews.com/api/zgvmqye_o_qv\")\n",
    "\n",
    "# You can try other news websites as well:\n",
    "\n",
    "# feed = feedparser.parse(\"https://www.aljazeera.com/xml/rss/all.xml\")\n",
    "# feed = feedparser.parse(\"http://rss.cnn.com/rss/edition_europe.rss\")\n",
    "\n",
    "feed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e431dc",
   "metadata": {},
   "source": [
    "Hint: You can try the following ways in order to get a website's RSS feed:\n",
    "\n",
    "- If the website is powered by Wordpress, you can do it by adding /feed/ at the end of its URL. Trying /rss/ is another option.\n",
    "<img src='images/rss_logo.png' style='height: 50px; float: right; margin-left: 50px' >\n",
    "- If you see the standard orange RSS logo, by simply clicking on it you will be taken to the website's RSS feed.\n",
    "- You can also use the page source: right click on the page and choose page source. In the new window, use ctrl+f and type in RSS. You’ll find the feed’s URL between the quotes after **href=**.\n",
    "\n",
    "The parse method fetches the feed from the provided URL, extracts the information in a systematic way and stores each piece in a structured format. At the high level, it returns a python dictionary with multiple keys and values, in which each value may contain python lists or other dictionaries. You can access the keys using the **keys()** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd44f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feed.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6810a7",
   "metadata": {},
   "source": [
    "Using these keys, we can access the more specific information that we want. The most common keys that can be used for extracting information are **entries** and **feed**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a7703",
   "metadata": {},
   "source": [
    "### 2.0.2 Extracting the contents from the feed\n",
    "We will start with the **entries** key. We can get the list of all the posts/podcasts/entries or any other form of content the feed is serving for, from the **entries** key in the dictionary. More information on other possible keys in the returned dictionary can be found [here](https://feedparser.readthedocs.io/en/latest/reference.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feed['entries']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524fd40",
   "metadata": {},
   "source": [
    "We can get the number of articles/entries using the **len()** function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab3a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feed['entries'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f528aa",
   "metadata": {},
   "source": [
    "#### Getting details of the entries\n",
    "We can iterate over the items of the entries list and print them to get more details on each article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fefd893",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in feed['entries']:\n",
    "    print (entry)\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140dac73",
   "metadata": {},
   "source": [
    "As we can see, each entry in the list is a dictionary again, which has different key-value pairs like **title**, **summary**, **link**, etc. We can again use the **keys()** method in order to explore the keys of the new dictionary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c40680",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feed['entries'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105af85d",
   "metadata": {},
   "source": [
    "Now that we have all the keys associated with the entries, we can extract the specific information like title, author, and actual contents of the feed.\n",
    "Though this might not be the same for all RSS feeds, it might be very similar and a matter of using the right keyword for the associated keys in the list of dictionaries.\n",
    "\n",
    "Let's say, we want to print out the titles of all the entries in the feed. We can do that by iterating over the entries list and fetching the title from the iterator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a49ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in feed.entries:\n",
    "    print (entry.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334eb28e",
   "metadata": {},
   "source": [
    "Similarly, we can get the links or the summaries of the entries using the link key in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fedfe6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for entry in feed.entries:\n",
    "    print (entry.link)\n",
    "    \n",
    "# for entry in feed.entries:\n",
    "#     print (entry.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f0ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09370b8",
   "metadata": {},
   "source": [
    "## 2.1. HTML for Web Scraping\n",
    "\n",
    "<img src='images/html.png' style='height: 90px; float: right; margin-left: 50px' >\n",
    "\n",
    "The **HyperText Markup Language** or **HTML** is the standard markup language for documents designed to be \n",
    "displayed in a web browser. It can be assisted by technologies such as Cascading Style Sheets (CSS) and scripting languages such as JavaScript. While the main content of the web pages are in the form of HTML, CSS add styling to the pages to make them look nicer and JavaScript files add interactivity to them.\n",
    "\n",
    "\n",
    "HTML code consists of a series of **elements**, and these elements tell the browser how to display the content. For collecting data from HTML web pages, it's necessary to have an idea of how this element syntax works.\n",
    "\n",
    "## 2.2. HTML Element Syntax [<a href='#destination2'>4</a>] <a id='destination2_'></a>\n",
    "\n",
    "HTML language can be applied to pieces of text to give them different meanings in a document (Is it a paragraph? Is it a bulleted list? Is it part of a table?), structure a document into logical sections (Does it have a header? Three columns of content? A navigation menu?), and embed content such as images and videos into a page. In this section we will introduce the first two of these, together with the fundamental concepts and syntax you need to know to understand HTML.\n",
    "\n",
    "To get started, we will begin with defining elements, attributes, and some other important terms. We will also explain where these fit into HTML. You will learn how HTML elements are structured, how a typical HTML page is structured, and other important basic language features.\n",
    "\n",
    "As already mentioned, HTML is a markup language that tells web browsers how to structure the web pages you visit. It can be as complicated or as simple as the web developer wants it to be. HTML consists of a series of elements, which you use to enclose, wrap, or mark up different parts of content to make it appear or act in a certain way. The enclosing tags can make content into a hyperlink to connect to another page, italicize words, and so on. For example, consider the following line of text:\n",
    "\n",
    "`My cat is very grumpy`\n",
    "\n",
    "If we wanted the text to stand by itself, we could specify that it is a paragraph by enclosing it in a paragraph (`<p>`) element:\n",
    "\n",
    "`<p>My cat is very grumpy</p>`\n",
    "\n",
    "<font color='darkblue'>**Note**: Tags in HTML are not case-sensitive, but it's better to write all of them in lower case for the sake of consistency and readability.\n",
    "</font>\n",
    "\n",
    "###  Anatomy of an HTML element\n",
    "\n",
    "Let's further explore our paragraph element mentioned above:\n",
    "\n",
    "<img src='images/html4.png' width=\"500\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "The anatomy of our element is:\n",
    "\n",
    "- **The opening tag**: This consists of the name of the element (in this example, p for paragraph), wrapped in opening and closing angle brackets. This opening tag marks where the element begins or starts to take effect. In this example, it precedes the start of the paragraph text.\n",
    "\n",
    "\n",
    "- **The content**: This is the content of the element. In this example, it is the paragraph text.\n",
    "\n",
    "\n",
    "- **The closing tag**: This is the same as the opening tag, except that it includes a forward slash before the element name. This marks where the element ends. Failing to include a closing tag is a common beginner error that can produce peculiar results.\n",
    "\n",
    "So, *the element* is the opening tag, followed by content, followed by the closing tag.\n",
    "\n",
    "**Create your first HTML element:**  Edit the `html` string below (it contains an HTML code) and get the actual rendered HTML output from `HTML()`. You can wrap the text of your choice with the tags `<em>` and `</em>`. Doing this should give the line italic text formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "596764a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<em>This is my text.</em>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = \"<em>This is my text.</em>\"\n",
    "HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a452d1",
   "metadata": {},
   "source": [
    "### Nesting elements\n",
    "\n",
    "Elements can be placed within other elements. This is called *nesting*. If we wanted to state that our cat is **very** grumpy, we could wrap the word \"very\" in a `<strong>` element, which means that the word is to have strong(er) text formatting:\n",
    "\n",
    "`<p>My cat is <strong>very</strong> grumpy.</p>`\n",
    "\n",
    "There is a right and wrong way to do nesting. In the example above, we opened the `p` element first, then opened the `strong` element. For proper nesting, we should close the `strong` element first, before closing the `p`.\n",
    "The following is an example of the *wrong* way to do nesting:\n",
    "\n",
    "`<p>My cat is <strong>very grumpy.</p></strong>`\n",
    "\n",
    "<u>The tags have to open and close in a way that they are inside or outside one another.</u> With the kind of overlap in the example above, the browser has to guess at your intent. This kind of guessing can lead to unexpected results.\n",
    "\n",
    "### Block versus inline elements\n",
    "\n",
    "There are two important categories of elements to know in HTML: block-level elements and inline elements.\n",
    "\n",
    "- Block-level elements form a visible block on a page. A block-level element appears on a new line following the content that precedes it. Any content that follows a block-level element also appears on a new line. Block-level elements are usually structural elements on the page. For example, a block-level element might represent headings, paragraphs, lists, navigation menus, or footers. A block-level element wouldn't be nested inside an inline element, but it might be nested inside another block-level element.\n",
    "\n",
    "\n",
    "- Inline elements are contained within block-level elements, and surround only small parts of the document's content (not entire paragraphs or groupings of content). An inline element will not cause a new line to appear in the document. It is typically used with text, for example an `<a>` element creates a hyperlink, and elements such as `<em>` or `<strong>` create emphasis.\n",
    "\n",
    "Consider the following example:\n",
    "\n",
    "`<em>first</em><em>second</em><em>third</em>`\n",
    "\n",
    "`<p>fourth</p><p>fifth</p><p>sixth</p>`\n",
    "\n",
    "`<em>` is an inline element. As you can see below, the first three elements sit on the same line, with no space in between. On the other hand, `<p>` is a block-level element. Each p element appears on a new line, with space above and below. (The spacing is due to default CSS styling that the browser applies to paragraphs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554ec810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<em>first</em><em>second</em><em>third</em>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"<em>first</em><em>second</em><em>third</em>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd38d21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>fourth</p><p>fifth</p><p>sixth</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"<p>fourth</p><p>fifth</p><p>sixth</p>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27958786",
   "metadata": {},
   "source": [
    "### Empty elements\n",
    "\n",
    "Not all elements follow the pattern of an opening tag, content, and a closing tag. Some elements consist of a single tag, which is typically used to insert/embed something in the document. For example, the `<img>` element embeds an image file onto a page:\n",
    "\n",
    "`<img src=\"https://raw.githubusercontent.com/mdn/beginner-html-site/gh-pages/images/firefox-icon.png\">`\n",
    "\n",
    "This would output the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b04245c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/mdn/beginner-html-site/gh-pages/images/firefox-icon.png\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<img src=\"https://raw.githubusercontent.com/mdn/beginner-html-site/gh-pages/images/firefox-icon.png\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e23fd2f",
   "metadata": {},
   "source": [
    "### Attributes\n",
    "\n",
    "Elements can also have attributes. Attributes look like this:\n",
    "\n",
    "<img src='images/html5.png' width=\"800\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "Attributes contain extra information about the element that won't appear in the content. In this example, the `class` attribute is an identifying name used to target the element with style information.\n",
    "\n",
    "An attribute should have:\n",
    "\n",
    "- A space between it and the element name. (For an element with more than one attribute, the attributes should be separated by spaces too.)\n",
    "- The attribute name, followed by an equal sign.\n",
    "- An attribute value, wrapped with opening and closing quote marks.\n",
    "\n",
    "**Adding attributes to an element**: Another example of an element is `<a>`. This stands for *anchor*. An anchor can make the text it encloses into a hyperlink. Anchors can take a number of attributes, but several are as follows:\n",
    "\n",
    "- `href`: This attribute's value specifies the web address for the link. For example: `href=\"https://www.mozilla.org/\"`\n",
    "- `title`: The `title` attribute specifies extra information about the link, such as a description of the page that is being linked to. For example, `title=\"The Mozilla homepage\"`. This appears as a tooltip when a cursor hovers over the element.\n",
    "- `target`: The `target` attribute specifies the browsing context used to display the link. For example, `target=\"_blank\"` will display the link in a new tab. If you want to display the linked content in the current tab, just omit this attribute.\n",
    "\n",
    "You can edit the `html` string below to turn it into a link to your favorite website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa22ad75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>A link to my <a href=\"https://www.mozilla.org/\" title=\"The Mozilla homepage\" target=\"_blank\">favorite website</a>.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = '<p>A link to my <a href=\"https://www.mozilla.org/\" title=\"The Mozilla homepage\" target=\"_blank\">favorite website</a>.</p>'\n",
    "HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d6efa",
   "metadata": {},
   "source": [
    "### Anatomy of an HTML document\n",
    "\n",
    "Individual HTML elements aren't very useful on their own. Next, let's examine how individual elements combine to form an entire HTML page:\n",
    "\n",
    "```\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en-US\">\n",
    "  <head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>My test page</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <p>This is my page</p>\n",
    "  </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "Here we have:\n",
    "\n",
    "1. `<!DOCTYPE html>`: The doctype. When HTML was young (1991-1992), doctypes were meant to act as links to a set of rules that the HTML page had to follow to be considered good HTML. More recently, the doctype is a historical artifact that needs to be included for everything else to work right. `<!DOCTYPE html>` is the shortest string of characters that counts as a valid doctype. That is all you need to know!\n",
    "\n",
    "\n",
    "2. `<html></html>`: The `<html>` element. This element wraps all the content on the page. It is sometimes known as the root element.\n",
    "\n",
    "\n",
    "3. `<head></head>`: The `<head>` element. This element acts as a container for everything you want to include on the HTML page, **that isn't the content** the page will show to viewers. This includes keywords and a page description that would appear in search results, CSS to style content, character set declarations, and more. You will learn more about this in the next article of the series.\n",
    "\n",
    "\n",
    "4. `<meta charset=\"utf-8\">`: The `<meta>` element. This element represents metadata that cannot be represented by other HTML meta-related elements, like `<base>`, `<link>`, `<script>`, `<style>` or `<title>`. The charset attributes sets the character set for your document to UTF-8, which includes most characters from the vast majority of human written languages. With this setting, the page can now handle any textual content it might contain. There is no reason not to set this, and it can help avoid some problems later.\n",
    "\n",
    "\n",
    "5. `<title></title>`: The `<title>` element. This sets the title of the page, which is the title that appears in the browser tab the page is loaded in. The page title is also used to describe the page when it is bookmarked.\n",
    "\n",
    "\n",
    "6. `<body></body>`: The `<body>` element. This contains all the content that displays on the page, including text, images, videos, games, playable audio tracks, or whatever else.\n",
    "\n",
    "Later in this notebook, you will get to explore HTML codes in more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b11b87",
   "metadata": {},
   "source": [
    "## 2.3 HTML Tree Structure [<a href='#destination3'>5</a>] <a id='destination3_'></a>\n",
    " \n",
    "Each HTML document can actually be referred to as a document tree. We describe the elements in the tree like we would describe a family tree. There are ancestors, descendants, parents, children and siblings.\n",
    "\n",
    "Use the sample HTML document below for the following examples. The `<head>` section of the document is omitted for brevity.\n",
    "\n",
    "```\n",
    "<body>\n",
    "\n",
    "  <div id=\"content\">\n",
    "    <h1>Heading here</h1>\n",
    "    <p>Lorem ipsum dolor sit amet.</p>\n",
    "    <p>Lorem ipsum dolor <em>sit</em> amet.</p>\n",
    "    <hr>\n",
    "  </div>\n",
    "  \n",
    "  <div id=\"nav\">\n",
    "    <ul>\n",
    "      <li>item 1</li>\n",
    "      <li>item 2</li>\n",
    "      <li>item 3</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "</body>\n",
    "```\n",
    "\n",
    "A diagram of the above HTML document tree would look like this:\n",
    "\n",
    "<img src='images/tree1.gif' width=\"435\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "### Ancestor\n",
    "\n",
    "An ancestor refers to any element that is connected but further up the document tree - no matter how many levels higher.\n",
    "\n",
    "In the diagram below, the `<body>` element is the ancestor of all other elements on the page.\n",
    "\n",
    "<img src='images/tree_ancestor.gif' width=\"435\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "### Descendant\n",
    "\n",
    "A descendant refers to any element that is connected but lower down the document tree - no matter how many levels lower.\n",
    "In the diagram below, all elements that are connected below the `<div>` element are descendants of that `<div>`.\n",
    "\n",
    "<img src='images/tree_descendant.gif' width=\"435\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "### Parent and Child\n",
    "\n",
    "A parent is an element that is directly above and connected to an element in the document tree. In the diagram below, the `<div>` is a parent to the `<ul>`.\n",
    "\n",
    "A child is an element that is directly below and connected to an element in the document tree. In the diagram above, the `<ul>` is a child to the `<div>`.\n",
    "\n",
    "<img src='images/tree_parent.gif' width=\"435\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "### Sibling\n",
    "\n",
    "A sibling is an element that shares the same parent with another element.\n",
    "\n",
    "In the diagram below, the `<li>`s are siblings as they all share the same parent - the `<ul>`.\n",
    "\n",
    "<img src='images/tree_siblings.gif' width=\"435\" height=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526fc121",
   "metadata": {},
   "source": [
    "# 3. Beautiful Soup\n",
    "<img src='images/bs.png' style='height: 150px; float: right; margin-left: 0px' >\n",
    "\n",
    "Beautiful Soup is a library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser, providing pythonic idioms for iterating, searching, and modifying the parse tree.\n",
    "\n",
    "\n",
    "Now that you have an idea of how HTML webpages are structured, we can start working with Beautiful Soup. We will go through some of the most important methods of it, and then you will get to write your first scraping project.\n",
    "\n",
    "\n",
    "\n",
    "If you don't have the package installed on your system, do it using `pip`, and then import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79049b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96b69e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1cf9bf",
   "metadata": {},
   "source": [
    "## 3.1 Basics [<a href='#destination4'>6, 7</a>] <a id='destination4_'></a>\n",
    "\n",
    "We will begin with an example page at http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html.\n",
    "\n",
    "The HTML source code of the page is stored in the `content` string as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c71a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"<html>\n",
    "<head>\n",
    "<title>A simple example page</title>\n",
    "</head>\n",
    "<body>\n",
    "<div>\n",
    "<p class=\"inner-text first-item\" id=\"first\">\n",
    "                First paragraph.\n",
    "            </p>\n",
    "<p class=\"inner-text\">\n",
    "                Second paragraph.\n",
    "            </p>\n",
    "</div>\n",
    "<p class=\"outer-text first-item\" id=\"second\">\n",
    "<b>\n",
    "                First outer paragraph.\n",
    "            </b>\n",
    "</p>\n",
    "<p class=\"outer-text\">\n",
    "<b>\n",
    "                Second outer paragraph.\n",
    "            </b>\n",
    "</p>\n",
    "</body>\n",
    "</html>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd0168fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>\n",
       "<p class=\"inner-text\">\n",
       "                Second paragraph.\n",
       "            </p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                First outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                Second outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML (content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f585526",
   "metadata": {},
   "source": [
    "### requests \n",
    "\n",
    "You can get the same content by fetching the page through `requests`. It is a simple and useful HTTP library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d149d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")\n",
    "content = page.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f5fff",
   "metadata": {},
   "source": [
    "By printing `page`, you can check to see if fetching the contents has been successful. The status code of \"200\" means you are good to go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79f09151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(page)\n",
    "# print(page.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50800ce3",
   "metadata": {},
   "source": [
    "### html parser\n",
    "\n",
    "By using its HTML parser, Beautiful Soup transforms a complex HTML document into a tree of python objects, so we can manage working with it easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cdffe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ff2709e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>\n",
       "<p class=\"inner-text\">\n",
       "                Second paragraph.\n",
       "            </p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                First outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                Second outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364711e0",
   "metadata": {},
   "source": [
    "Using `soup.pretiffy()`, we can have a better tree overview of the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23a675de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   A simple example page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <div>\n",
      "   <p class=\"inner-text first-item\" id=\"first\">\n",
      "    First paragraph.\n",
      "   </p>\n",
      "   <p class=\"inner-text\">\n",
      "    Second paragraph.\n",
      "   </p>\n",
      "  </div>\n",
      "  <p class=\"outer-text first-item\" id=\"second\">\n",
      "   <b>\n",
      "    First outer paragraph.\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"outer-text\">\n",
      "   <b>\n",
      "    Second outer paragraph.\n",
      "   </b>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print (soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434bde9f",
   "metadata": {},
   "source": [
    "Each tag can now be viewed as an object. We can also access all children objects of a tag using dots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2bfe331",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " <div>\n",
       " <p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>\n",
       " <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>\n",
       " </div>,\n",
       " '\\n',\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " '\\n',\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.html.body.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4868f",
   "metadata": {},
   "source": [
    "### find() & find_all()\n",
    "\n",
    "Two  of the most important methods of Beautiful Soup are its `find` and `find_all()` methods.\n",
    "\n",
    "`find()` method finds the first occurence of a certain tag matching the given criteria. Its first argument is the tag name, so if we pass `p` as a string to it, it will return the first occurence of the `p` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99b99e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c87b7",
   "metadata": {},
   "source": [
    "As you can see, the output is the same as when we use a dot for accessing the `p` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a55e8f15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaebdce1",
   "metadata": {},
   "source": [
    "With the `find_all()` method, we can get a list of all of the occurences of a certain tag matching the given criteria. Again, if we pass the \"p\" string to it, it will return all the occurences of the `p` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e10d0f8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>,\n",
       " <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>,\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "929d4a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all('p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e147bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552891f0",
   "metadata": {},
   "source": [
    "We can also specify attribute values and pass them to the method. The following line of code returns the list of all the `p` tags whose values for the `class` attribute is `\"outer-text\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7488c8d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', {'class': \"outer-text\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9037c67",
   "metadata": {},
   "source": [
    "This one returns the list of all tags whose `id` attributes equal `\"first\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ac01b56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e5483d",
   "metadata": {},
   "source": [
    "### select()\n",
    "\n",
    "Beautiful Soup has a `select()` method which uses the [SoupSieve](https://facelessuser.github.io/soupsieve/) package to run a CSS selector against a parsed document and return all the matching elements.\n",
    "\n",
    "The SoupSieve documentation lists all the currently supported CSS selectors, but here are some of the basics;\n",
    "\n",
    "You can find tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cddc3fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>,\n",
       " <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>,\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7b8925",
   "metadata": {},
   "source": [
    "You can find tags beneath other tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7590441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>,\n",
       " <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"div p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f8b7f",
   "metadata": {},
   "source": [
    "You can find tags with specific classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "012c9da4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>,\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"p.first-item\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1351d88e",
   "metadata": {},
   "source": [
    "You can find tags by id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "23cfe757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"#second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c981b8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"p#second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d251f31f",
   "metadata": {},
   "source": [
    "And you can also find tags by a combination of the above-mentioned criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2a46b664",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"div p.first-item#first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e129a42",
   "metadata": {},
   "source": [
    "### get_text()\n",
    "\n",
    "If you only want the human-readable text inside a document or tag, you can use the get_text() method. It returns all the text in a document or beneath a tag, as a single Unicode string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d7cda836",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nA simple example page\\n\\n\\n\\n\\n                First paragraph.\\n            \\n\\n                Second paragraph.\\n            \\n\\n\\n\\n                First outer paragraph.\\n            \\n\\n\\n\\n                Second outer paragraph.\\n            \\n\\n\\n'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07354c5d",
   "metadata": {},
   "source": [
    "You can tell Beautiful Soup to strip whitespace from the beginning and end of each bit of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a99ff3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A simple example pageFirst paragraph.Second paragraph.First outer paragraph.Second outer paragraph.'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.get_text(strip = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de00d2",
   "metadata": {},
   "source": [
    "You can also specify a string to be used to join the bits of text together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "549f42af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A simple example page|First paragraph.|Second paragraph.|First outer paragraph.|Second outer paragraph.'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.get_text(\"|\", strip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b3c5c6",
   "metadata": {},
   "source": [
    "But at that point you might want to use the `stripped_strings` generator instead, and process the text yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dbdfa59c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A simple example page',\n",
       " 'First paragraph.',\n",
       " 'Second paragraph.',\n",
       " 'First outer paragraph.',\n",
       " 'Second outer paragraph.']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[text for text in soup.stripped_strings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f68c312",
   "metadata": {},
   "source": [
    "## 3.2 Scraping data from Aljazeera [<a href='#destination5'>8</a>] <a id='destination5_'></a>\n",
    "\n",
    "<img src='images/aljazeera.png' style='height: 150px; float: right; margin-left: 50px' >\n",
    "\n",
    "Now that you are familiar with the basics of Beautiful Soup, we can do a more practical scraping project. We will collect some news data from [aljazeera.com](https://www.aljazeera.com), and you will get to examine what you have learnt so far.\n",
    "\n",
    "To have a better idea of what exactly we are going to do, open the website, use the search bar and search \"Turkey\". In the new page, sort the retrieved news articles by date. As you can see, the 10 most recent news articles related to Turkey are now displayed. We are going to scrape and store them in a pandas dataframe.\n",
    "\n",
    "First, we need to make sure we have all the necessary packages available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1db3c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5a3fa7",
   "metadata": {},
   "source": [
    "We make an *html* directory and an *articles.html* file for downloads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ac4f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory if it doesn't exist yet:\n",
    "directory = \"html\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "filename = directory + \"/articles.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4184c6",
   "metadata": {},
   "source": [
    "Then we construct the right URL from `path` and `searchterm`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d0bbf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"https://www.aljazeera.com/search/\"\n",
    "searchterm = \"Turkey\"\n",
    "parameters = \"?sort=date\"\n",
    "url = path + searchterm + parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8a65bf",
   "metadata": {},
   "source": [
    "The resulting URL is the same as that of the page you explored at the first stage. Now we fetch it using `requests`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d745cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e63b40d",
   "metadata": {},
   "source": [
    "We check to see if we get the right status code (200), then we save the contents of the page in *articles.html*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8acf8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if page.status_code == 200:\n",
    "    with open(filename, 'wb') as file:\n",
    "        file.write(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546cc00a",
   "metadata": {},
   "source": [
    "Then we parse the webpage with Beautiful Soup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3989cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(open(filename, encoding=\"utf-8\"),'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9807c",
   "metadata": {},
   "source": [
    "Now that we have the page parsed, we need to select the right elements of it to extract our desired information from. In the simple webpage that we investigated in the Beautiful Soup Basics section, it was easy to pick the right elements to investigate from the few lines of code. In real HTML web pages it's a bit different.\n",
    "\n",
    "In order to find the right elemets, right-click somewhere on the page and click on *inspect*. Then press Ctrl+Shift+C. Now you should be able to inspect the page and see the HTML code for each part of the page you hover the mouse. Equivalently, by hovering the mouse on certain lines of HTML code you can see what that code actually creates on the page.\n",
    "\n",
    "On Google Chrome it would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c581548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.aljazeera.com/search/Turkey?sort=date'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada2f2a",
   "metadata": {},
   "source": [
    "<img src='images/inspect.png' style='height: 550px; float: right; margin-left: 50px' >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffdd488",
   "metadata": {},
   "source": [
    "It turns out that the elements that we would like to work on are the ones with the `article` tags. We'll select them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ca690fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = soup.select('article')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527828c",
   "metadata": {},
   "source": [
    "Next, we will scrape different information from the articles. We do that by putting every article's title, text and URL in a corresponding dictionary, and will add all the dictionaries to the `results` list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4c96262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty list for results\n",
    "results = []\n",
    "\n",
    "for article in articles: \n",
    "    \n",
    "    # Initialize empty dictionary\n",
    "    # Extract title, text and URL of articles \n",
    "    item = {}\n",
    "    item['title'] = article.select_one('span').text.strip()\n",
    "    item['text'] = article.select_one('p').text.strip()    \n",
    "    item['url'] = article.select_one('a').get('href')\n",
    "    # You can also get the URLs with article.select_one('a')['href']\n",
    "    \n",
    "    # Append items to result-list\n",
    "    results.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ebddb4",
   "metadata": {},
   "source": [
    "At last, we convert the results list to a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "657e7f2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iraq | To­day's lat­est from Al Jazeera</td>\n",
       "      <td>21 hours ago ... Iran clos­es its bor­der with...</td>\n",
       "      <td>https://www.aljazeera.com/where/iraq/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mid­dle East News | To­day's lat­est from Al J...</td>\n",
       "      <td>21 hours ago ... Stay on top of Mid­dle East l...</td>\n",
       "      <td>https://www.aljazeera.com/middle-east/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eu­rope News | To­day's lat­est from Al Jazeera</td>\n",
       "      <td>21 hours ago ... Stay on top of Eu­rope lat­es...</td>\n",
       "      <td>https://www.aljazeera.com/europe/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uighurs de­mand ac­count­abil­i­ty af­ter UN r...</td>\n",
       "      <td>11 hours ago ... Uighur rights groups say UN r...</td>\n",
       "      <td>https://www.aljazeera.com/news/2022/9/1/uighur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UN head hopes Chi­na will 'take on board' Xin­...</td>\n",
       "      <td>3 hours ago ... Mean­while, Uighurs in­ter­vie...</td>\n",
       "      <td>https://www.aljazeera.com/news/2022/9/1/un-hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rus­sia starts mas­sive war games with Chi­na ...</td>\n",
       "      <td>13 hours ago ... Pub­lished On 1 Sep 20221 Sep...</td>\n",
       "      <td>https://www.aljazeera.com/news/2022/9/1/russia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UN re­port on Xin­jiang ups pres­sure on brand...</td>\n",
       "      <td>14 hours ago ... Pub­lished On 1 Sep 20221 Sep...</td>\n",
       "      <td>https://www.aljazeera.com/economy/2022/9/1/un-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lat­est Ukraine up­dates: IAEA to main­tain pr...</td>\n",
       "      <td>11 hours ago ... A car­go ship car­ry­ing 3,00...</td>\n",
       "      <td>https://www.aljazeera.com/news/liveblog/2022/9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dozens of civil­ians killed in April by Mal­i'...</td>\n",
       "      <td>1 day ago ... ... against hu­man­i­ty' in Chi­...</td>\n",
       "      <td>https://www.aljazeera.com/news/2022/8/31/at-le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>At least 14 dead in rebel at­tacks in east­ern...</td>\n",
       "      <td>1 day ago ... Eth­nic Uighur demon­stra­tors t...</td>\n",
       "      <td>https://www.aljazeera.com/news/2022/8/31/at-le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0            Iraq | To­day's lat­est from Al Jazeera   \n",
       "1  Mid­dle East News | To­day's lat­est from Al J...   \n",
       "2    Eu­rope News | To­day's lat­est from Al Jazeera   \n",
       "3  Uighurs de­mand ac­count­abil­i­ty af­ter UN r...   \n",
       "4  UN head hopes Chi­na will 'take on board' Xin­...   \n",
       "5  Rus­sia starts mas­sive war games with Chi­na ...   \n",
       "6  UN re­port on Xin­jiang ups pres­sure on brand...   \n",
       "7  Lat­est Ukraine up­dates: IAEA to main­tain pr...   \n",
       "8  Dozens of civil­ians killed in April by Mal­i'...   \n",
       "9  At least 14 dead in rebel at­tacks in east­ern...   \n",
       "\n",
       "                                                text  \\\n",
       "0  21 hours ago ... Iran clos­es its bor­der with...   \n",
       "1  21 hours ago ... Stay on top of Mid­dle East l...   \n",
       "2  21 hours ago ... Stay on top of Eu­rope lat­es...   \n",
       "3  11 hours ago ... Uighur rights groups say UN r...   \n",
       "4  3 hours ago ... Mean­while, Uighurs in­ter­vie...   \n",
       "5  13 hours ago ... Pub­lished On 1 Sep 20221 Sep...   \n",
       "6  14 hours ago ... Pub­lished On 1 Sep 20221 Sep...   \n",
       "7  11 hours ago ... A car­go ship car­ry­ing 3,00...   \n",
       "8  1 day ago ... ... against hu­man­i­ty' in Chi­...   \n",
       "9  1 day ago ... Eth­nic Uighur demon­stra­tors t...   \n",
       "\n",
       "                                                 url  \n",
       "0              https://www.aljazeera.com/where/iraq/  \n",
       "1             https://www.aljazeera.com/middle-east/  \n",
       "2                  https://www.aljazeera.com/europe/  \n",
       "3  https://www.aljazeera.com/news/2022/9/1/uighur...  \n",
       "4  https://www.aljazeera.com/news/2022/9/1/un-hea...  \n",
       "5  https://www.aljazeera.com/news/2022/9/1/russia...  \n",
       "6  https://www.aljazeera.com/economy/2022/9/1/un-...  \n",
       "7  https://www.aljazeera.com/news/liveblog/2022/9...  \n",
       "8  https://www.aljazeera.com/news/2022/8/31/at-le...  \n",
       "9  https://www.aljazeera.com/news/2022/8/31/at-le...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266ec10d",
   "metadata": {},
   "source": [
    "## 3.3 Toy example: Scraping Chief Seattle Speech\n",
    "\n",
    "As another small example of working with BeautifulSoup, we will scrape the text from the Chief Seattle Speech from [This link](https://suquamish.nsn.us/home/about-us/chief-seattle-speech/). Try openning the page and see how it looks!\n",
    "\n",
    "Like before, we first get the contents of the page using `requests` and `BeautifulSoup`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6e8b349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\"https://suquamish.nsn.us/home/about-us/chief-seattle-speech/\")\n",
    "print(page)\n",
    "content = page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74b4a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "# soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7741aabd",
   "metadata": {},
   "source": [
    "If you `inspect` the page, you will see that the main text of the whole page is structured under `section` tag. For accessing the main text all at once, you can simply use the `get_text()` method on this tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ff36867",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yonder sky that has wept tears of compassion upon my people for centuries untold, and which to us appears changeless and eternal, may change. Today is fair. Tomorrow it may be overcast with clouds. My words are like the stars that never change. Whatever Seattle says, the great chief at Washington can rely upon with as much certainty as he can upon the return of the sun or the seasons. The white chief says that Big Chief at Washington sends us greetings of friendship and goodwill. This is kind of him for we know he has little need of our friendship in return. His people are many. They are like the grass that covers vast prairies. My people are few. They resemble the scattering trees of a storm-swept plain. The great, and I presume — good, White Chief sends us word that he wishes to buy our land but is willing to allow us enough to live comfortably. This indeed appears just, even generous, for the Red Man no longer has rights that he need respect, and the offer may be wise, also, as we are no longer in need of an extensive country.\\nThere was a time when our people covered the land as the waves of a wind-ruffled sea cover its shell-paved floor, but that time long since passed away with the greatness of tribes that are now but a mournful memory. I will not dwell on, nor mourn over, our untimely decay, nor reproach my paleface brothers with hastening it, as we too may have been somewhat to blame.\\nYouth is impulsive. When our young men grow angry at some real or imaginary wrong, and disfigure their faces with black paint, it denotes that their hearts are black, and that they are often cruel and relentless, and our old men and old women are unable to restrain them. Thus it has ever been. Thus it was when the white man began to push our forefathers ever westward. But let us hope that the hostilities between us may never return. We would have everything to lose and nothing to gain. Revenge by young men is considered gain, even at the cost of their own lives, but old men who stay at home in times of war, and mothers who have sons to lose, know better.\\nOur good father in Washington–for I presume he is now our father as well as yours, since King George has moved his boundaries further north–our great and good father, I say, sends us word that if we do as he desires he will protect us. His brave warriors will be to us a bristling wall of strength, and his wonderful ships of war will fill our harbors, so that our ancient enemies far to the northward — the Haidas and Tsimshians — will cease to frighten our women, children, and old men. Then in reality he will be our father and we his children. But can that ever be? Your God is not our God! Your God loves your people and hates mine! He folds his strong protecting arms lovingly about the paleface and leads him by the hand as a father leads an infant son. But, He has forsaken His Red children, if they really are His. Our God, the Great Spirit, seems also to have forsaken us. Your God makes your people wax stronger every day. Soon they will fill all the land. Our people are ebbing away like a rapidly receding tide that will never return. The white man’s God cannot love our people or He would protect them. They seem to be orphans who can look nowhere for help. How then can we be brothers? How can your God become our God and renew our prosperity and awaken in us dreams of returning greatness? If we have a common Heavenly Father He must be partial, for He came to His paleface children. We never saw Him. He gave you laws but had no word for His red children whose teeming multitudes once filled this vast continent as stars fill the firmament. No; we are two distinct races with separate origins and separate destinies. There is little in common between us.\\nTo us the ashes of our ancestors are sacred and their resting place is hallowed ground. You wander far from the graves of your ancestors and seemingly without regret. Your religion was written upon tablets of stone by the iron finger of your God so that you could not forget. The Red Man could never comprehend or remember it. Our religion is the traditions of our ancestors — the dreams of our old men, given them in solemn hours of the night by the Great Spirit; and the visions of our sachems, and is written in the hearts of our people.\\nYour dead cease to love you and the land of their nativity as soon as they pass the portals of the tomb and wander away beyond the stars. They are soon forgotten and never return. Our dead never forget this beautiful world that gave them being. They still love its verdant valleys, its murmuring rivers, its magnificent mountains, sequestered vales and verdant lined lakes and bays, and ever yearn in tender fond affection over the lonely hearted living, and often return from the happy hunting ground to visit, guide, console, and comfort them.\\nDay and night cannot dwell together. The Red Man has ever fled the approach of the White Man, as the morning mist flees before the morning sun. However, your proposition seems fair and I think that my people will accept it and will retire to the reservation you offer them. Then we will dwell apart in peace, for the words of the Great White Chief seem to be the words of nature speaking to my people out of dense darkness.\\nIt matters little where we pass the remnant of our days. They will not be many. The Indian’s night promises to be dark. Not a single star of hope hovers above his horizon. Sad-voiced winds moan in the distance. Grim fate seems to be on the Red Man’s trail, and wherever he will hear the approaching footsteps of his fell destroyer and prepare stolidly to meet his doom, as does the wounded doe that hears the approaching footsteps of the hunter.\\nA few more moons, a few more winters, and not one of the descendants of the mighty hosts that once moved over this broad land or lived in happy homes, protected by the Great Spirit, will remain to mourn over the graves of a people once more powerful and hopeful than yours. But why should I mourn at the untimely fate of my people? Tribe follows tribe, and nation follows nation, like the waves of the sea. It is the order of nature, and regret is useless. Your time of decay may be distant, but it will surely come, for even the White Man whose God walked and talked with him as friend to friend, cannot be exempt from the common destiny. We may be brothers after all. We will see.\\nWe will ponder your proposition and when we decide we will let you know. But should we accept it, I here and now make this condition that we will not be denied the privilege without molestation of visiting at any time the tombs of our ancestors, friends, and children. Every part of this soil is sacred in the estimation of my people. Every hillside, every valley, every plain and grove, has been hallowed by some sad or happy event in days long vanished. Even the rocks, which seem to be dumb and dead as the swelter in the sun along the silent shore, thrill with memories of stirring events connected with the lives of my people, and the very dust upon which you now stand responds more lovingly to their footsteps than yours, because it is rich with the blood of our ancestors, and our bare feet are conscious of the sympathetic touch. Our departed braves, fond mothers, glad, happy hearted maidens, and even the little children who lived here and rejoiced here for a brief season, will love these somber solitudes and at eventide they greet shadowy returning spirits. And when the last Red Man shall have perished, and the memory of my tribe shall have become a myth among the White Men, these shores will swarm with the invisible dead of my tribe, and when your children’s children think themselves alone in the field, the store, the shop, upon the highway, or in the silence of the pathless woods, they will not be alone. In all the earth there is no place dedicated to solitude. At night when the streets of your cities and villages are silent and you think them deserted, they will throng with the returning hosts that once filled them and still love this beautiful land. The White Man will never be alone.\\nLet him be just and deal kindly with my people, for the dead are not powerless. Dead, did I say? There is no death, only a change of worlds.\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.section.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d528087",
   "metadata": {},
   "source": [
    "There are also multiple `p` tags under the `sectoin` tag, each containing a single paragraph in the page. So, for accessing a certain paragraph, what you need to do is getting the corresponding `p` tag first, and then extracting its text using `get_text()`.\n",
    "\n",
    "Let's store the contents of `section` tag in the `soup2` list first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c634813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = soup.section.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc5739",
   "metadata": {},
   "source": [
    "As you can see, we have 9 different paragraphs in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff5e9082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48e3f6e",
   "metadata": {},
   "source": [
    "Now, let's say we want to access the text of the 3rd paragraph. We can get that by using the `get_text()` method on the 3rd item of `soup2`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6206ca09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our good father in Washington–for I presume he is now our father as well as yours, since King George has moved his boundaries further north–our great and good father, I say, sends us word that if we do as he desires he will protect us. His brave warriors will be to us a bristling wall of strength, and his wonderful ships of war will fill our harbors, so that our ancient enemies far to the northward — the Haidas and Tsimshians — will cease to frighten our women, children, and old men. Then in reality he will be our father and we his children. But can that ever be? Your God is not our God! Your God loves your people and hates mine! He folds his strong protecting arms lovingly about the paleface and leads him by the hand as a father leads an infant son. But, He has forsaken His Red children, if they really are His. Our God, the Great Spirit, seems also to have forsaken us. Your God makes your people wax stronger every day. Soon they will fill all the land. Our people are ebbing away like a rapidly receding tide that will never return. The white man’s God cannot love our people or He would protect them. They seem to be orphans who can look nowhere for help. How then can we be brothers? How can your God become our God and renew our prosperity and awaken in us dreams of returning greatness? If we have a common Heavenly Father He must be partial, for He came to His paleface children. We never saw Him. He gave you laws but had no word for His red children whose teeming multitudes once filled this vast continent as stars fill the firmament. No; we are two distinct races with separate origins and separate destinies. There is little in common between us.\\nTo us the ashes of our ancestors are sacred and their resting place is hallowed ground. You wander far from the graves of your ancestors and seemingly without regret. Your religion was written upon tablets of stone by the iron finger of your God so that you could not forget. The Red Man could never comprehend or remember it. Our religion is the traditions of our ancestors — the dreams of our old men, given them in solemn hours of the night by the Great Spirit; and the visions of our sachems, and is written in the hearts of our people.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2[2].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6182d3a1",
   "metadata": {},
   "source": [
    "<img src='images/selenium.png' style='height: 100px; float: right; margin-left: 100px' >\n",
    "\n",
    "# 4. Selenium "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c76de5",
   "metadata": {},
   "source": [
    "# 5. Scrapy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425df720",
   "metadata": {},
   "source": [
    "# 6. Challanges\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe29c81",
   "metadata": {},
   "source": [
    "# 7. References\n",
    "\n",
    "[<a href='#destination1_'>1</a>] https://pypi.org/project/feedparser/ <a id='destination1'></a>\n",
    "\n",
    "[<a href='#destination1_'>2</a>] https://rss.com/blog/find-rss-feed/#:~:text=Right%20click%20on%20the%20website's,between%20the%20quotes%20after%20href%3D\n",
    "\n",
    "[<a href='#destination1_'>3</a>] https://dev.to/mr_destructive/feedparser-python-package-for-reading-rss-feeds-5fnc\n",
    "\n",
    "[<a href='#destination2_'>4</a>] https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction_to_HTML/Getting_started <a id='destination2'></a>\n",
    "\n",
    "[<a href='#destination3_'>5</a>] http://web.simmons.edu/~grabiner/comm244/weekfour/document-tree.html <a id='destination3'></a>\n",
    "\n",
    "[<a href='#destination4_'>6</a>] https://www.crummy.com/software/BeautifulSoup/bs4/doc/ <a id='destination4'></a>\n",
    "\n",
    "[<a href='#destination4_'>7</a>] Fabian's notebook from GESIS fall seminar 2021: https://colab.research.google.com/drive/1uKxOc8mXTE2b05uUq-YlijJYzOTgi5DZ#scrollTo=ao_sLGiOSu7Y\n",
    "\n",
    "[<a href='#destination5_'>8</a>] The Social Comquant Workshop 10 at https://github.com/strohne/autocol <a id='destination5'></a>\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "https://www.dataquest.io/blog/web-scraping-python-using-beautiful-soup/#tve-jump-1788432a71d\n",
    "\n",
    "https://developer.mozilla.org/en-US/docs/Web/HTML/Element\n",
    "\n",
    "https://medium.com/geekculture/web-scraping-cheat-sheet-2021-python-for-web-scraping-cad1540ce21c#b81d\n",
    "\n",
    "https://trends.google.com/trends/yis/2021/DE/\n",
    "\n",
    "https://blog.google/products/search/15-tips-getting-most-out-google-trends/\n",
    "\n",
    "\n",
    "Do not miss checking out the Social Comquant Workshop 10 at: https://github.com/strohne/autocol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2453c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
