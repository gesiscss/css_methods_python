{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "583054cb",
   "metadata": {},
   "source": [
    "# 2. Data handling and visualization\n",
    "\n",
    "IN GENERAL: INTRODUCE THINGS HERE WHICH WE NEED IN SESSIONS 3-14. THAT MEANS, WHENEVER WE \n",
    "\n",
    "### Textbooks & sources\n",
    "\n",
    "- https://jakevdp.github.io/PythonDataScienceHandbook/\n",
    "- https://www.pythonlikeyoumeanit.com/index.html\n",
    "\n",
    "### Notes\n",
    "\n",
    "- Focus here is on flat data structures (Pandas dataframes) and mathematical data structures (NumPy arrays), add also regex here instead of showing them in the functions of NLP?; hierarchical data structures (JSON and HTML) are covered in session 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ee36b8",
   "metadata": {},
   "source": [
    "## 2.1. Essentials\n",
    "\n",
    "https://www.pythonlikeyoumeanit.com/module_2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef5d9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01c1fb32",
   "metadata": {},
   "source": [
    "BOX: OBJECT-ORIENTED PROGRAMING\n",
    "https://www.pythonlikeyoumeanit.com/module_4.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab7bdd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "106768e0",
   "metadata": {},
   "source": [
    "## 2.2. Pandas\n",
    "\n",
    "- https://jakevdp.github.io/PythonDataScienceHandbook/03.00-introduction-to-pandas.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d5945",
   "metadata": {},
   "source": [
    "### 2.2.1. TweetsCOV19 dataset\n",
    "\n",
    "https://data.gesis.org/tweetscov19/\n",
    "\n",
    "- Tweet Id: Long.\n",
    "- Username: String. Encrypted for privacy issues.\n",
    "- Timestamp: Format ( \"EEE MMM dd HH:mm:ss Z yyyy\" ).\n",
    "- #Followers: Integer.\n",
    "- #Friends: Integer.\n",
    "- #Retweets: Integer.\n",
    "- #Favorites: Integer.\n",
    "- Entities: String. For each entity, we aggregated the original text, the annotated entity and the produced score from FEL library. Each entity is separated from another entity by char \";\". Also, each entity is separated by char \":\" in order to store \"original_text:annotated_entity:score;\". If FEL did not find any entities, we have stored \"null;\".\n",
    "- Sentiment: String. SentiStrength produces a score for positive (1 to 5) and negative (-1 to -5) sentiment. We splitted these two numbers by whitespace char \" \". Positive sentiment was stored first and then negative sentiment (i.e. \"2 -1\").\n",
    "- Mentions: String. If the tweet contains mentions, we remove the char \"@\" and concatenate the mentions with whitespace char \" \". If no mentions appear, we have stored \"null;\".\n",
    "- Hashtags: String. If the tweet contains hashtags, we remove the char \"#\" and concatenate the hashtags with whitespace char \" \". If no hashtags appear, we have stored \"null;\".\n",
    "- URLs: String: If the tweet contains URLs, we concatenate the URLs using \":-: \". If no URLs appear, we have stored \"null;\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308ecd27",
   "metadata": {},
   "source": [
    "Download the file https://zenodo.org/record/4593502/files/TweetsCOV19_052020.tsv.gz and store it in the data/tweetscov19/ directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304ef30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d492dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('data/data', sep='\\t', header=None, quoting= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a177acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.columns = ['tweet_id', 'username', 'timestamp', 'followers', 'friends', 'retweets', 'favorites', 'entities', 'sentiment', 'mentions', 'hashtags', 'urls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b45808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Splitting 'sentiment' into pos and neg and deleting 'sentiment' column:\n",
    "\n",
    "pos = []\n",
    "neg = []\n",
    "\n",
    "for i in tweets['sentiment']:\n",
    "    pos.append(i.split()[0])\n",
    "    neg.append(i.split()[1])\n",
    "    \n",
    "tweets['sentiment_pos'] = pos\n",
    "tweets['sentiment_neg'] = neg\n",
    "\n",
    "del tweets['sentiment']\n",
    "\n",
    "# tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad679a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting values of hashtags column into lists:\n",
    "# Note: 'null;' and NaN values are replaced with ['']\n",
    "\n",
    "def f1(cell):\n",
    "    if cell == 'null;' or type(cell) == float:\n",
    "#     if type(cell) == float:\n",
    "        cell = ['']\n",
    "    else:\n",
    "        cell = cell.split()\n",
    "    return cell\n",
    "\n",
    "tweets['hashtags'] = tweets['hashtags'].apply(f1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Putting values of mentions column into lists:\n",
    "# Note: 'null;' and NaN values are replaced with ['']\n",
    "\n",
    "tweets['mentions'] = tweets['mentions'].apply(f1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Putting values of entities column into lists:\n",
    "# Note: 'null;' values are replaced with ['']\n",
    "\n",
    "def f2(cell):\n",
    "    if cell == 'null;':\n",
    "        cell = ['']\n",
    "    else:\n",
    "        splitted = cell.split(';')\n",
    "        del splitted[-1]\n",
    "        cell = splitted\n",
    "        \n",
    "    return cell\n",
    "\n",
    "tweets['entities'] = tweets['entities'].apply(f2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Putting values of urls column into lists:\n",
    "# Note: 'null;' and NaN values are replaced with ['']\n",
    "\n",
    "def f3(cell):\n",
    "    if cell == 'null;' or type(cell) == float:\n",
    "        cell = ['']\n",
    "    else:\n",
    "        splitted = cell.split(':-:')\n",
    "        del splitted[-1]\n",
    "        cell = splitted\n",
    "        \n",
    "    return cell\n",
    "\n",
    "tweets['urls'] = tweets['urls'].apply(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34ea75e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>followers_max</th>\n",
       "      <th>friends_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1d4d177b4028f2b6ea90a3617c32fb6</td>\n",
       "      <td>117926717</td>\n",
       "      <td>606040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0b64e075d55e5221457d3e22ba3dcc14</td>\n",
       "      <td>111636059</td>\n",
       "      <td>299530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7cd534d396546a50ddd2dea9ee7f9145</td>\n",
       "      <td>108555597</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a075253a703c963c96f819be90e82a67</td>\n",
       "      <td>81495144</td>\n",
       "      <td>123005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75224fc65ae453fe9ec3ca855cd8619b</td>\n",
       "      <td>80751709</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117996</th>\n",
       "      <td>cf8eeb9a12741558dd0b7bad7e7a1d63</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117997</th>\n",
       "      <td>6a16d1b50cb0b7eb0afec535b5957ab5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117998</th>\n",
       "      <td>cf8f99bc1f576ca2d4adcb4611754c46</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117999</th>\n",
       "      <td>cf914bf27fee569df7b1d8ffffbf9cb5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118000</th>\n",
       "      <td>57de5b6e7caadc47935e434ad13d319e</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1118001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 username  followers_max  friends_max\n",
       "0        c1d4d177b4028f2b6ea90a3617c32fb6      117926717       606040\n",
       "1        0b64e075d55e5221457d3e22ba3dcc14      111636059       299530\n",
       "2        7cd534d396546a50ddd2dea9ee7f9145      108555597          224\n",
       "3        a075253a703c963c96f819be90e82a67       81495144       123005\n",
       "4        75224fc65ae453fe9ec3ca855cd8619b       80751709           46\n",
       "...                                   ...            ...          ...\n",
       "1117996  cf8eeb9a12741558dd0b7bad7e7a1d63              0            6\n",
       "1117997  6a16d1b50cb0b7eb0afec535b5957ab5              0            2\n",
       "1117998  cf8f99bc1f576ca2d4adcb4611754c46              0            4\n",
       "1117999  cf914bf27fee569df7b1d8ffffbf9cb5              0            0\n",
       "1118000  57de5b6e7caadc47935e434ad13d319e              0           95\n",
       "\n",
       "[1118001 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating users dataframe:\n",
    "\n",
    "# Note: This may take around 90 seconds to run\n",
    "\n",
    "followers_max = tweets.loc[tweets.groupby('username')['followers'].idxmax()]\n",
    "followers_max = followers_max.reset_index()\n",
    "\n",
    "friends_max = tweets.loc[tweets.groupby('username')['friends'].idxmax()]\n",
    "friends_max = friends_max.reset_index()\n",
    "\n",
    "users = pd.DataFrame()\n",
    "users['username'] = friends_max['username']\n",
    "users['followers_max'] = followers_max['followers']\n",
    "users['friends_max'] = friends_max['friends']\n",
    "users = users.sort_values('followers_max', ascending = False).reset_index()\n",
    "del users['index']\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b062a00b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>followers</th>\n",
       "      <th>friends</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>sentiment_pos</th>\n",
       "      <th>sentiment_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1255980246995570692</td>\n",
       "      <td>219284</td>\n",
       "      <td>Thu Apr 30 22:00:00 +0000 2020</td>\n",
       "      <td>1714</td>\n",
       "      <td>112</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1255980246370676737</td>\n",
       "      <td>9835</td>\n",
       "      <td>Thu Apr 30 22:00:00 +0000 2020</td>\n",
       "      <td>200432</td>\n",
       "      <td>1880</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1255980246559408128</td>\n",
       "      <td>47478</td>\n",
       "      <td>Thu Apr 30 22:00:00 +0000 2020</td>\n",
       "      <td>26865</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1255980248161714177</td>\n",
       "      <td>11861</td>\n",
       "      <td>Thu Apr 30 22:00:00 +0000 2020</td>\n",
       "      <td>140395</td>\n",
       "      <td>350</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1255980247683674113</td>\n",
       "      <td>377</td>\n",
       "      <td>Thu Apr 30 22:00:00 +0000 2020</td>\n",
       "      <td>6149624</td>\n",
       "      <td>462</td>\n",
       "      <td>32</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912065</th>\n",
       "      <td>1267214225283231744</td>\n",
       "      <td>753448</td>\n",
       "      <td>Sun May 31 21:59:49 +0000 2020</td>\n",
       "      <td>149</td>\n",
       "      <td>341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912066</th>\n",
       "      <td>1267214225270685696</td>\n",
       "      <td>789381</td>\n",
       "      <td>Sun May 31 21:59:49 +0000 2020</td>\n",
       "      <td>118</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912067</th>\n",
       "      <td>1267214229469310978</td>\n",
       "      <td>322385</td>\n",
       "      <td>Sun May 31 21:59:50 +0000 2020</td>\n",
       "      <td>1465</td>\n",
       "      <td>1566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912068</th>\n",
       "      <td>1267214242060500992</td>\n",
       "      <td>413803</td>\n",
       "      <td>Sun May 31 21:59:53 +0000 2020</td>\n",
       "      <td>892</td>\n",
       "      <td>1080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912069</th>\n",
       "      <td>1267214242052288520</td>\n",
       "      <td>700722</td>\n",
       "      <td>Sun May 31 21:59:53 +0000 2020</td>\n",
       "      <td>205</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1912070 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  identifier  user_id                       timestamp  \\\n",
       "0        1255980246995570692   219284  Thu Apr 30 22:00:00 +0000 2020   \n",
       "1        1255980246370676737     9835  Thu Apr 30 22:00:00 +0000 2020   \n",
       "2        1255980246559408128    47478  Thu Apr 30 22:00:00 +0000 2020   \n",
       "3        1255980248161714177    11861  Thu Apr 30 22:00:00 +0000 2020   \n",
       "4        1255980247683674113      377  Thu Apr 30 22:00:00 +0000 2020   \n",
       "...                      ...      ...                             ...   \n",
       "1912065  1267214225283231744   753448  Sun May 31 21:59:49 +0000 2020   \n",
       "1912066  1267214225270685696   789381  Sun May 31 21:59:49 +0000 2020   \n",
       "1912067  1267214229469310978   322385  Sun May 31 21:59:50 +0000 2020   \n",
       "1912068  1267214242060500992   413803  Sun May 31 21:59:53 +0000 2020   \n",
       "1912069  1267214242052288520   700722  Sun May 31 21:59:53 +0000 2020   \n",
       "\n",
       "         followers  friends  retweets  favorites sentiment_pos sentiment_neg  \n",
       "0             1714      112        37         46             2            -1  \n",
       "1           200432     1880        14         50             2            -3  \n",
       "2            26865       80         1          0             1            -3  \n",
       "3           140395      350         2          4             1            -1  \n",
       "4          6149624      462        32        104             1            -1  \n",
       "...            ...      ...       ...        ...           ...           ...  \n",
       "1912065        149      341         0          0             2            -3  \n",
       "1912066        118      419         0          0             1            -4  \n",
       "1912067       1465     1566         0          0             1            -1  \n",
       "1912068        892     1080         0          0             2            -1  \n",
       "1912069        205      218         0          0             3            -1  \n",
       "\n",
       "[1912070 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tweets dataframe:\n",
    "\n",
    "# Note: This may take around 35 seconds to run.\n",
    "\n",
    "tweets_table = tweets.copy()\n",
    "tweets_table.rename(columns = {'tweet_id':'identifier', 'username':'user_id'}, inplace = True)\n",
    "\n",
    "temp_users = users.reset_index()\n",
    "del temp_users['followers_max']\n",
    "del temp_users['friends_max']\n",
    "\n",
    "merged = pd.merge(temp_users, tweets_table, left_on='username', right_on='user_id', how='left').drop('user_id', axis=1)\n",
    "# del temp_users\n",
    "merged = merged.rename(columns={\"index\": \"user_id\"})\n",
    "del merged['username']\n",
    "\n",
    "modified_timestamps = pd.to_datetime(merged['timestamp'], format = '%a %b %d %X %z %Y')\n",
    "\n",
    "merged['modified_timestamps'] = modified_timestamps\n",
    "merged = merged.sort_values(by=['modified_timestamps']).reset_index()\n",
    "del merged['modified_timestamps']\n",
    "del merged['index']\n",
    "\n",
    "cols = ['identifier'] + ['user_id'] + [col for col in merged if (col != 'identifier' and col != 'user_id')]\n",
    "merged = merged[cols]\n",
    "tweets_sorted = merged\n",
    "tweets_table = tweets_sorted.copy()\n",
    "\n",
    "del tweets_table['entities']\n",
    "del tweets_table['mentions']\n",
    "del tweets_table['hashtags']\n",
    "del tweets_table['urls']\n",
    "del merged\n",
    "\n",
    "tweets_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "093613d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities</th>\n",
       "      <th>original</th>\n",
       "      <th>annotated</th>\n",
       "      <th>score</th>\n",
       "      <th>selections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19:Coronavirus_disease_2019:-1.535776454...</td>\n",
       "      <td>covid 19</td>\n",
       "      <td>Coronavirus_disease_2019</td>\n",
       "      <td>-1.535776454600282</td>\n",
       "      <td>140954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quarantine:Quarantine:-2.3096035868012508</td>\n",
       "      <td>quarantine</td>\n",
       "      <td>Quarantine</td>\n",
       "      <td>-2.3096035868012508</td>\n",
       "      <td>71016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>china:China:-2.113921624336916</td>\n",
       "      <td>china</td>\n",
       "      <td>China</td>\n",
       "      <td>-2.113921624336916</td>\n",
       "      <td>57440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>social distancing:Social_distancing:-1.4103273...</td>\n",
       "      <td>social distancing</td>\n",
       "      <td>Social_distancing</td>\n",
       "      <td>-1.4103273474020743</td>\n",
       "      <td>38509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppe:Philosophy%2C_politics_and_economics:-2.48...</td>\n",
       "      <td>ppe</td>\n",
       "      <td>Philosophy%2C_politics_and_economics</td>\n",
       "      <td>-2.481280260595</td>\n",
       "      <td>16559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182410</th>\n",
       "      <td>cradle of civilization:Cradle_of_civilization:...</td>\n",
       "      <td>cradle of civilization</td>\n",
       "      <td>Cradle_of_civilization</td>\n",
       "      <td>-1.2882848955688024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182411</th>\n",
       "      <td>la ong fong:La-Ong-Fong:-2.6390572166801127</td>\n",
       "      <td>la ong fong</td>\n",
       "      <td>La-Ong-Fong</td>\n",
       "      <td>-2.6390572166801127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182412</th>\n",
       "      <td>john ward:John_Ward_%28umpire%29:-2.0444200293...</td>\n",
       "      <td>john ward</td>\n",
       "      <td>John_Ward_%28umpire%29</td>\n",
       "      <td>-2.0444200293125485</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182413</th>\n",
       "      <td>iqbal ahmed:Iqbal_Ahmed:-2.563177904831185</td>\n",
       "      <td>iqbal ahmed</td>\n",
       "      <td>Iqbal_Ahmed</td>\n",
       "      <td>-2.563177904831185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182414</th>\n",
       "      <td>tropicana field:Tropicana_Field:-0.75558133760...</td>\n",
       "      <td>tropicana field</td>\n",
       "      <td>Tropicana_Field</td>\n",
       "      <td>-0.7555813376025603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182415 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 entities  \\\n",
       "0       covid 19:Coronavirus_disease_2019:-1.535776454...   \n",
       "1               quarantine:Quarantine:-2.3096035868012508   \n",
       "2                          china:China:-2.113921624336916   \n",
       "3       social distancing:Social_distancing:-1.4103273...   \n",
       "4       ppe:Philosophy%2C_politics_and_economics:-2.48...   \n",
       "...                                                   ...   \n",
       "182410  cradle of civilization:Cradle_of_civilization:...   \n",
       "182411        la ong fong:La-Ong-Fong:-2.6390572166801127   \n",
       "182412  john ward:John_Ward_%28umpire%29:-2.0444200293...   \n",
       "182413         iqbal ahmed:Iqbal_Ahmed:-2.563177904831185   \n",
       "182414  tropicana field:Tropicana_Field:-0.75558133760...   \n",
       "\n",
       "                      original                             annotated  \\\n",
       "0                     covid 19              Coronavirus_disease_2019   \n",
       "1                   quarantine                            Quarantine   \n",
       "2                        china                                 China   \n",
       "3            social distancing                     Social_distancing   \n",
       "4                          ppe  Philosophy%2C_politics_and_economics   \n",
       "...                        ...                                   ...   \n",
       "182410  cradle of civilization                Cradle_of_civilization   \n",
       "182411             la ong fong                           La-Ong-Fong   \n",
       "182412               john ward                John_Ward_%28umpire%29   \n",
       "182413             iqbal ahmed                           Iqbal_Ahmed   \n",
       "182414         tropicana field                       Tropicana_Field   \n",
       "\n",
       "                      score  selections  \n",
       "0        -1.535776454600282      140954  \n",
       "1       -2.3096035868012508       71016  \n",
       "2        -2.113921624336916       57440  \n",
       "3       -1.4103273474020743       38509  \n",
       "4           -2.481280260595       16559  \n",
       "...                     ...         ...  \n",
       "182410  -1.2882848955688024           1  \n",
       "182411  -2.6390572166801127           1  \n",
       "182412  -2.0444200293125485           1  \n",
       "182413   -2.563177904831185           1  \n",
       "182414  -0.7555813376025603           1  \n",
       "\n",
       "[182415 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating entities dataframe:\n",
    "\n",
    "entities_table = pd.DataFrame()\n",
    "\n",
    "res = pd.DataFrame({'entities': np.concatenate(tweets['entities'].values)})\n",
    "entities_table['entities'] = res.squeeze().value_counts().index\n",
    "\n",
    "original = ['']\n",
    "annotated = ['']\n",
    "score = ['']\n",
    "\n",
    "for i in entities_table['entities'][1:]:      \n",
    "          \n",
    "    split = i.split(':')\n",
    "    original.append(split[0])\n",
    "    annotated.append(split[1])\n",
    "    score.append(split[2])\n",
    "\n",
    "entities_table['original'] = original\n",
    "entities_table['annotated'] = annotated\n",
    "entities_table['score'] = score\n",
    "\n",
    "entities_table['selections'] = res.squeeze().value_counts().reindex().to_numpy()\n",
    "\n",
    "entities_table = entities_table.drop(entities_table.index[0]).reset_index()\n",
    "del entities_table['index']\n",
    "    \n",
    "entities_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90439569",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mentions</th>\n",
       "      <th>selections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>37878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMOIndia</td>\n",
       "      <td>6361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>narendramodi</td>\n",
       "      <td>6342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jaketapper</td>\n",
       "      <td>5892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YouTube</td>\n",
       "      <td>5658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678371</th>\n",
       "      <td>ListenShahid1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678372</th>\n",
       "      <td>Fingerz00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678373</th>\n",
       "      <td>AinsleyFoods</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678374</th>\n",
       "      <td>ImtiazTyab</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678375</th>\n",
       "      <td>lsddrq</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>678376 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               mentions  selections\n",
       "0       realDonaldTrump       37878\n",
       "1              PMOIndia        6361\n",
       "2          narendramodi        6342\n",
       "3            jaketapper        5892\n",
       "4               YouTube        5658\n",
       "...                 ...         ...\n",
       "678371    ListenShahid1           1\n",
       "678372        Fingerz00           1\n",
       "678373     AinsleyFoods           1\n",
       "678374       ImtiazTyab           1\n",
       "678375           lsddrq           1\n",
       "\n",
       "[678376 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating mentions dataframe:\n",
    "\n",
    "mentions_table = pd.DataFrame()\n",
    "\n",
    "res = pd.DataFrame({'mentions': np.concatenate(tweets['mentions'].values)})\n",
    "mentions_table['mentions'] = res.squeeze().value_counts().index\n",
    "\n",
    "mentions_table['selections'] = res.squeeze().value_counts().reindex().to_numpy()\n",
    "\n",
    "mentions_table = mentions_table.drop(mentions_table.index[0]).reset_index()\n",
    "del mentions_table['index']\n",
    "\n",
    "mentions_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3000b49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>selections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID19</td>\n",
       "      <td>67421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coronavirus</td>\n",
       "      <td>30332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Covid_19</td>\n",
       "      <td>11032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid19</td>\n",
       "      <td>10648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>null;</td>\n",
       "      <td>9477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351602</th>\n",
       "      <td>BeckettandQuarantine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351603</th>\n",
       "      <td>366DaysOfWords</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351604</th>\n",
       "      <td>Pioppi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351605</th>\n",
       "      <td>PhotographyGame</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351606</th>\n",
       "      <td>okpanam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351607 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    hashtags  selections\n",
       "0                    COVID19       67421\n",
       "1                coronavirus       30332\n",
       "2                   Covid_19       11032\n",
       "3                    covid19       10648\n",
       "4                      null;        9477\n",
       "...                      ...         ...\n",
       "351602  BeckettandQuarantine           1\n",
       "351603        366DaysOfWords           1\n",
       "351604                Pioppi           1\n",
       "351605       PhotographyGame           1\n",
       "351606               okpanam           1\n",
       "\n",
       "[351607 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating hashtags dataframe:\n",
    "\n",
    "hashtags_table = pd.DataFrame()\n",
    "\n",
    "res = pd.DataFrame({'hashtags': np.concatenate(tweets['hashtags'].values)})\n",
    "hashtags_table['hashtags'] = res.squeeze().value_counts().index\n",
    "\n",
    "hashtags_table['selections'] = res.squeeze().value_counts().reindex().to_numpy()\n",
    "\n",
    "hashtags_table = hashtags_table.drop(hashtags_table.index[0]).reset_index()\n",
    "del hashtags_table['index']\n",
    "\n",
    "hashtags_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "856a44d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urls</th>\n",
       "      <th>selections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.twittascope.com/?sign=5</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.whatsapp.com/send?phone=9190393567...</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://rebrand.ly/work-2020</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.twittascope.com/?sign=6</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://redcross.give.asia/campaign/essentials...</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420617</th>\n",
       "      <td>https://baltimore.cbslocal.com/2020/05/23/ocea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420618</th>\n",
       "      <td>https://mol.im/a/8350307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420619</th>\n",
       "      <td>https://iq.cash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420620</th>\n",
       "      <td>https://block.fiverr.com/index.html?url=aHR0cD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420621</th>\n",
       "      <td>https://vt.tiktok.com/S3oVHj/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420622 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     urls  selections\n",
       "0                     https://www.twittascope.com/?sign=5         549\n",
       "1       https://api.whatsapp.com/send?phone=9190393567...         368\n",
       "2                             http://rebrand.ly/work-2020         286\n",
       "3                     https://www.twittascope.com/?sign=6         271\n",
       "4       https://redcross.give.asia/campaign/essentials...         260\n",
       "...                                                   ...         ...\n",
       "420617  https://baltimore.cbslocal.com/2020/05/23/ocea...           1\n",
       "420618                           https://mol.im/a/8350307           1\n",
       "420619                                    https://iq.cash           1\n",
       "420620  https://block.fiverr.com/index.html?url=aHR0cD...           1\n",
       "420621                      https://vt.tiktok.com/S3oVHj/           1\n",
       "\n",
       "[420622 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating urls dataframe:\n",
    "\n",
    "urls_table = pd.DataFrame()\n",
    "\n",
    "urls1 = pd.DataFrame()\n",
    "urls1['urls'] = tweets['urls']\n",
    "\n",
    "urls2 = pd.DataFrame()\n",
    "\n",
    "for i in range (10):\n",
    "    \n",
    "    temp_df = urls1[i*(int(urls1.shape[0]/10)):i*(int(urls1.shape[0]/10))+int(urls1.shape[0]/10)]\n",
    "    res = pd.DataFrame({'urls': np.concatenate(temp_df['urls'].values)})\n",
    "    urls2 = pd.concat([urls2, res], ignore_index = True, axis = 0)\n",
    "\n",
    "urls_table['urls'] = urls2.squeeze().value_counts().index\n",
    "\n",
    "urls_table['selections'] = urls2.squeeze().value_counts().reindex().to_numpy()\n",
    "\n",
    "urls_table = urls_table.drop(urls_table.index[0]).reset_index()\n",
    "del urls_table['index']\n",
    "\n",
    "urls_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5de611b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>entity_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>9942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>9554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757735</th>\n",
       "      <td>1912060</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757736</th>\n",
       "      <td>1912061</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757737</th>\n",
       "      <td>1912061</td>\n",
       "      <td>1752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757738</th>\n",
       "      <td>1912061</td>\n",
       "      <td>130908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757739</th>\n",
       "      <td>1912062</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2757740 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id  entity_id\n",
       "0               0      16611\n",
       "1               0       6716\n",
       "2               0        383\n",
       "3               1       9942\n",
       "4               2       9554\n",
       "...           ...        ...\n",
       "2757735   1912060         16\n",
       "2757736   1912061        851\n",
       "2757737   1912061       1752\n",
       "2757738   1912061     130908\n",
       "2757739   1912062        462\n",
       "\n",
       "[2757740 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tweets_entities dataframe:\n",
    "\n",
    "tweets_entities = tweets_sorted['entities'].reset_index()\n",
    "\n",
    "lens = list(map(len, tweets_entities['entities'].values))\n",
    "tweets_entities = pd.DataFrame({'tweet_id': np.repeat(tweets_entities['index'], lens), 'entities': np.concatenate(tweets_entities['entities'].values)})\n",
    "\n",
    "entities_table = entities_table.reset_index()\n",
    "tweets_entities = tweets_entities[tweets_entities.entities != '']\n",
    "\n",
    "merged = pd.merge(entities_table, tweets_entities, left_on='entities', right_on='entities', how='right')\n",
    "\n",
    "merged.rename(columns = {'index':'entity_id'}, inplace = True)\n",
    "\n",
    "del merged['entities']\n",
    "del merged['original']\n",
    "del merged['annotated']\n",
    "del merged['score']\n",
    "del merged['selections']\n",
    "\n",
    "cols = ['tweet_id'] + ['entity_id']\n",
    "merged = merged[cols]\n",
    "tweets_entities = merged.copy()\n",
    "\n",
    "del entities_table['index']\n",
    "\n",
    "tweets_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "004b7b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>hashtag_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>179308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551213</th>\n",
       "      <td>1912035</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551214</th>\n",
       "      <td>1912035</td>\n",
       "      <td>4688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551215</th>\n",
       "      <td>1912047</td>\n",
       "      <td>9525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551216</th>\n",
       "      <td>1912051</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551217</th>\n",
       "      <td>1912054</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1551218 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id  hashtag_id\n",
       "0               0         438\n",
       "1               1      179308\n",
       "2               1        8943\n",
       "3               1       14935\n",
       "4               1       10668\n",
       "...           ...         ...\n",
       "1551213   1912035         241\n",
       "1551214   1912035        4688\n",
       "1551215   1912047        9525\n",
       "1551216   1912051         674\n",
       "1551217   1912054         600\n",
       "\n",
       "[1551218 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tweets_hashtags dataframe:\n",
    "\n",
    "tweets_hashtags = tweets_sorted['hashtags'].reset_index()\n",
    "\n",
    "lens = list(map(len, tweets_hashtags['hashtags'].values))\n",
    "tweets_hashtags = pd.DataFrame({'tweet_id': np.repeat(tweets_hashtags['index'], lens), 'hashtags': np.concatenate(tweets_hashtags['hashtags'].values)})\n",
    "\n",
    "hashtags_table = hashtags_table.reset_index()\n",
    "tweets_hashtags = tweets_hashtags[tweets_hashtags.hashtags != '']\n",
    "\n",
    "merged = pd.merge(hashtags_table, tweets_hashtags, left_on='hashtags', right_on='hashtags', how='right')\n",
    "\n",
    "merged.rename(columns = {'index':'hashtag_id'}, inplace = True)\n",
    "del merged['hashtags']\n",
    "del merged['selections']\n",
    "\n",
    "cols = ['tweet_id'] + ['hashtag_id']\n",
    "merged = merged[cols]\n",
    "tweets_hashtags = merged.copy()\n",
    "\n",
    "del hashtags_table['index']\n",
    "\n",
    "tweets_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46026876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>mention_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>29152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>108796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>15649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>440995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>435743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009441</th>\n",
       "      <td>1912060</td>\n",
       "      <td>90696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009442</th>\n",
       "      <td>1912061</td>\n",
       "      <td>392590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009443</th>\n",
       "      <td>1912061</td>\n",
       "      <td>392589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009444</th>\n",
       "      <td>1912061</td>\n",
       "      <td>42533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009445</th>\n",
       "      <td>1912061</td>\n",
       "      <td>6463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2009446 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id  mention_id\n",
       "0               3       29152\n",
       "1               8      108796\n",
       "2               9       15649\n",
       "3              13      440995\n",
       "4              17      435743\n",
       "...           ...         ...\n",
       "2009441   1912060       90696\n",
       "2009442   1912061      392590\n",
       "2009443   1912061      392589\n",
       "2009444   1912061       42533\n",
       "2009445   1912061        6463\n",
       "\n",
       "[2009446 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tweets_mentions dataframe:\n",
    "\n",
    "tweets_mentions = tweets_sorted['mentions'].reset_index()\n",
    "\n",
    "lens = list(map(len, tweets_mentions['mentions'].values))\n",
    "tweets_mentions = pd.DataFrame({'tweet_id': np.repeat(tweets_mentions['index'], lens), 'mentions': np.concatenate(tweets_mentions['mentions'].values)})\n",
    "\n",
    "mentions_table = mentions_table.reset_index()\n",
    "tweets_mentions = tweets_mentions[tweets_mentions.mentions != '']\n",
    "\n",
    "merged = pd.merge(mentions_table, tweets_mentions, left_on='mentions', right_on='mentions', how='right')\n",
    "\n",
    "merged.rename(columns = {'index':'mention_id'}, inplace = True)\n",
    "\n",
    "del merged['mentions']\n",
    "del merged['selections']\n",
    "\n",
    "cols = ['tweet_id'] + ['mention_id']\n",
    "merged = merged[cols]\n",
    "tweets_mentions = merged.copy()\n",
    "\n",
    "del mentions_table['index']\n",
    "\n",
    "tweets_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c6f2f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>url_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>336798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>261083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534002</th>\n",
       "      <td>1912002</td>\n",
       "      <td>11972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534003</th>\n",
       "      <td>1912010</td>\n",
       "      <td>390206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534004</th>\n",
       "      <td>1912017</td>\n",
       "      <td>8366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534005</th>\n",
       "      <td>1912028</td>\n",
       "      <td>73475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534006</th>\n",
       "      <td>1912051</td>\n",
       "      <td>112875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534007 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_id  url_id\n",
       "0              0   64962\n",
       "1              2   11746\n",
       "2              3  336798\n",
       "3              4  261083\n",
       "4              5   44481\n",
       "...          ...     ...\n",
       "534002   1912002   11972\n",
       "534003   1912010  390206\n",
       "534004   1912017    8366\n",
       "534005   1912028   73475\n",
       "534006   1912051  112875\n",
       "\n",
       "[534007 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tweets_urls dataframe:\n",
    "\n",
    "tweets_urls = tweets_sorted['urls'].reset_index()\n",
    "\n",
    "\n",
    "\n",
    "urls1 = tweets_urls.copy()\n",
    "urls2 = pd.DataFrame()\n",
    "\n",
    "for i in range (10):   \n",
    "    temp_df = urls1[i*(int(urls1.shape[0]/10)):i*(int(urls1.shape[0]/10))+int(urls1.shape[0]/10)]   \n",
    "    lens = list(map(len, temp_df['urls'].values))\n",
    "    res = pd.DataFrame({'tweet_id': np.repeat(temp_df['index'], lens), 'urls': np.concatenate(temp_df['urls'].values)})    \n",
    "    urls2 = pd.concat([urls2, res], ignore_index = True, axis = 0)\n",
    "\n",
    "tweets_urls = urls2\n",
    "\n",
    "urls_table = urls_table.reset_index()\n",
    "tweets_urls = tweets_urls[tweets_urls.urls != '']\n",
    "\n",
    "merged = pd.merge(urls_table, tweets_urls, left_on='urls', right_on='urls', how='right')\n",
    "\n",
    "merged.rename(columns = {'index':'url_id'}, inplace = True)\n",
    "\n",
    "del merged['urls']\n",
    "del merged['selections']\n",
    "\n",
    "cols = ['tweet_id'] + ['url_id']\n",
    "merged = merged[cols]\n",
    "tweets_urls = merged.copy()\n",
    "\n",
    "del urls_table['index']\n",
    "\n",
    "tweets_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d85d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b89c9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfbc5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6ff08bf",
   "metadata": {},
   "source": [
    "### 2.2.2. Working with a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bed539cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read/save\n",
    "# describe()\n",
    "# changing index and column names\n",
    "# grouping\n",
    "# using and resetting the index\n",
    "# categorize series: categories and codes\n",
    "# matrix to edgelist and vice versa\n",
    "# zip\n",
    "# columns into dict\n",
    "# datetime\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046dfc35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e97bba6e",
   "metadata": {},
   "source": [
    "### 2.2.3. Working with multiple dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a707be06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge split concat etc\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f1685a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "444d7d2f",
   "metadata": {},
   "source": [
    "## 2.3. NumPy\n",
    "\n",
    "- https://jakevdp.github.io/PythonDataScienceHandbook/02.00-introduction-to-numpy.html\n",
    "- https://www.pythonlikeyoumeanit.com/module_3.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de4e272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read/save\n",
    "# relationship to pandas\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d20ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c96d75c4",
   "metadata": {},
   "source": [
    "## 2.4. SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f0b2b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse matrices\n",
    "# matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3a387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51e8cb38",
   "metadata": {},
   "source": [
    "## 2.5. Data visualiation with Seaborn & Matplotlib\n",
    "\n",
    "SUGGESTION: TEACH HOW TO WITH SEABORN, USE MATPLOTLIB WHERE SEABORN DOES NOT OFFER METHODS\n",
    "\n",
    "- https://jakevdp.github.io/PythonDataScienceHandbook/04.00-introduction-to-matplotlib.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c7ef61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b05aab6",
   "metadata": {},
   "source": [
    "## 2.6. Reading PDF files: *To be moved to a different section later*\n",
    "\n",
    "In this section, we introduce **PyPDF2** library, which is a free and open source pure-python PDF library capable of splitting, merging, cropping, and transforming the pages of PDF files. It has many other useful features for working with pdf files, but our emphasis here is on reading data from pdf files. For more information on all the capabilities you can take a look at [its documentation](https://pypdf2.readthedocs.io/en/latest/).\n",
    "\n",
    "You can install the library with `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6023077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /home/sed_zeppelin/anaconda3/lib/python3.8/site-packages (2.11.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /home/sed_zeppelin/anaconda3/lib/python3.8/site-packages (from PyPDF2) (4.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf80d6",
   "metadata": {},
   "source": [
    "### 2.6.1 Reading Metadata\n",
    "\n",
    "We'll begin with reading the metadata from a pdf file. We have used *Generative Adversarial Networks* paper by Ian Goodfellow as an example pdf file. You can use any other file of your own choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39dedf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "130d5c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"GAN.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ae08df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/CreationDate': \"D:20201006125850-04'00'\",\n",
       " '/Creator': 'Adobe InDesign 15.1 (Macintosh)',\n",
       " '/ModDate': \"D:20201006125856-04'00'\",\n",
       " '/Producer': 'Adobe PDF Library 15.0'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = reader.metadata\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eb366d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Adobe InDesign 15.1 (Macintosh)\n",
      "Adobe PDF Library 15.0\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(meta.author)\n",
    "print(meta.creator)\n",
    "print(meta.producer)\n",
    "print(meta.subject)\n",
    "print(meta.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a066800f",
   "metadata": {},
   "source": [
    "Please note that all of the above values could be `None` for your own pdf files. You can also write metadata in your pdf files, [here](https://pypdf2.readthedocs.io/en/latest/user/metadata.html) is how."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c224a17",
   "metadata": {},
   "source": [
    "### 2.6.2 Extracting Text from a PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e7176f",
   "metadata": {},
   "source": [
    "For accessing the pages of the pdf file, you can do the following:\n",
    "\n",
    "*Note: the `reader` variable is defined in the previous section.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f92a687e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = reader.pages\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb4525",
   "metadata": {},
   "source": [
    "You can access page number 10 this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed5149e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOVEMBER 2020  |  VOL. 63  |  NO. 11  |   COMMUNICATIONS OF THE ACM    139Generative Adversarial Networks\n",
      "By Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu,  \n",
      "David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua BengioDOI:10.1145/3422622\n",
      "Abstract\n",
      "Generative adversarial networks are a kind of artificial intel-\n",
      "ligence algorithm designed to solve the generative model-\n",
      "ing problem. The goal of a generative model is to study a \n",
      "collection of training examples and learn the probability \n",
      "distribution that generated them. Generative Adversarial \n",
      "Networks (GANs) are then able to generate more examples \n",
      "from the estimated probability distribution. Generative \n",
      "models based on deep learning are common, but GANs \n",
      "are among the most successful generative models (espe-\n",
      "cially in terms of their ability to generate realistic high-\n",
      "resolution images). GANs have been successfully applied \n",
      "to a wide variety of tasks (mostly in research settings) but \n",
      "continue to present unique challenges and research \n",
      "opportunities because they are based on game theory \n",
      "while most other approaches to generative modeling are \n",
      "based on optimization.\n",
      "1. INTRODUCTION\n",
      "Most current approaches to developing artificial intelli-\n",
      "gence are based primarily on machine learning. The most \n",
      "widely used and successful form of machine learning to date \n",
      "is supervised learning. Supervised learning algorithms are \n",
      "given a dataset of pairs of example inputs and example out-\n",
      "puts. They learn to associate each input with each output \n",
      "and thus learning a mapping from input to output exam-\n",
      "ples. The input examples are typically complicated data \n",
      "objects like images, natural language sentences, or audio \n",
      "waveforms, while the output examples are often relatively \n",
      "simple. The most common kind of supervised learning is \n",
      "classification, where the output is just an integer code iden-\n",
      "tifying a specific category (a photo might be recognized as \n",
      "coming from category 0 containing cats, or category 1 con-\n",
      "taining dogs, etc.).\n",
      "Supervised learning is often able to achieve greater than \n",
      "human accuracy after the training process is complete, and \n",
      "thus has been integrated into many products and services. \n",
      "Unfortunately, the learning process itself still falls far short \n",
      "of human abilities. Supervised learning by definition relies \n",
      "on a human supervisor to provide an output example for \n",
      "each input example. Worse, existing approaches to super-\n",
      "vised learning often require millions of training examples to \n",
      "exceed human performance, when a human might be able \n",
      "to learn to perform the task acceptably from a very small \n",
      "number of examples.\n",
      "In order to reduce both the amount of human supervi-\n",
      "sion required for learning and the number of examples \n",
      "required for learning, many researchers today study \n",
      "unsupervised learning, often using generative models. In \n",
      "this overview paper, we describe one particular approach \n",
      "to unsupervised learning via generative modeling called \n",
      "generative adversarial networks. We briefly review The original version of this paper is entitled “Generative \n",
      "Adversarial Networks” and was published in Advances in \n",
      "Neural Information Processing Systems 27 (NIPS 2014).applications of GANs and identify core research problems \n",
      "related to convergence in games necessary to make GANs a \n",
      "reliable technology.\n",
      "2. GENERATIVE MODELING\n",
      "The goal of supervised learning is relatively straightforward \n",
      "to specify, and all supervised learning algorithms have \n",
      "essentially the same goal: learn to accurately associate new \n",
      "input examples with the correct outputs. For instance, an \n",
      "object recognition algorithm may associate a photo of a dog \n",
      "with some kind of DOG category identifier.\n",
      "Unsupervised learning is a less clearly defined branch of \n",
      "machine learning, with many different unsupervised learn-\n",
      "ing algorithms pursuing many different goals. Broadly \n",
      "speaking, the goal of unsupervised learning is to learn some-\n",
      "thing useful by examining a dataset containing unlabeled \n",
      "input examples. Clustering and dimensionality reduction \n",
      "are common examples of unsupervised learning.\n",
      "Another approach to unsupervised learning is generative \n",
      "modeling. In generative modeling, training examples x are \n",
      "drawn from an unknown distribution pdata(x). The goal of a \n",
      "generative modeling algorithm is to learn a pmodel(x) that \n",
      "approximates pdata(x) as closely as possible.\n",
      "A straightforward way to learn an approximation of pdata is \n",
      "to explicitly write a function pmodel(x; θ) controlled by param-\n",
      "eters θ and search for the value of the parameters that makes \n",
      "pdata and pmodel as similar as possible. In particular, the most \n",
      "popular approach to generative modeling is probably maxi-\n",
      "mum likelihood estimation, consisting of minimizing the \n",
      "Kullback-Leibler divergence between pdata and pmodel. The \n",
      "common approach of estimating the mean parameter of a \n",
      "Gaussian distribution by taking the mean of a set of observa-\n",
      "tions is one example of maximum likelihood estimation. \n",
      "This approach based on explicit density functions is illus-\n",
      "trated in Figure 1.\n",
      "Explicit density modeling has worked well for traditional \n",
      "statistics, using simple functional forms of probability dis-\n",
      "tributions, usually applied to small numbers of variables. \n",
      "More recently, with the rise of machine learning in general \n",
      "and deep learning in particular, researchers have become \n",
      "interested in learning models that make use of relatively \n",
      "complicated functional forms. When a deep neural net-\n",
      "work is used to generate data, the corresponding density \n",
      "function may be computationally intractable. \n",
      "Traditionally, there have been two dominant approaches \n",
      "to confronting this intractability problem: (1) carefully \n",
      "design the model to have a tractable density function \n",
      "(e.g., Frey11) and (2) design a learning algorithm based on \n"
     ]
    }
   ],
   "source": [
    "print(pages[0].extract_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d2f0a",
   "metadata": {},
   "source": [
    "More information on the `extract_text()` method could be found [here](https://pypdf2.readthedocs.io/en/latest/modules/PageObject.html#PyPDF2._page.PageObject.extract_text)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38760fbd",
   "metadata": {},
   "source": [
    "#### Using a visitor\n",
    "\n",
    "\n",
    "You can use *visitor-functions* to control which part of a page you want to process and extract. The visitor-functions you provide will get called for each operator or for each text fragment.\n",
    "\n",
    "The function provided in argument `visitor_text` of method `extract_text()` has five arguments: current transformation matrix, text matrix, font-dictionary and font-size. In most cases the x and y coordinates of the current position are in index 4 and 5 of the current transformation matrix.\n",
    "\n",
    "The font-dictionary may be None in case of unknown fonts. If not None it may e.g. contain key “/BaseFont” with value “/Arial,Bold”.\n",
    "\n",
    "Warning: In complicated documents the calculated positions might be wrong.\n",
    "\n",
    "The function provided in argument `visitor_operand_before` has four arguments: operand, operand-arguments, current transformation matrix and text matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedd4687",
   "metadata": {},
   "source": [
    "#### Example: Ignoring header and footer\n",
    "\n",
    "In this example, we read the text of page 1 (with index = 0), but we ignore header (y < 670) and footer (y > 30)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "240abec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract\n",
      "Generative adversarial networks are a kind of artificial intel-\n",
      "ligence algorithm designed to solve the generative model-\n",
      "ing problem. The goal of a generative model is to study a \n",
      "collection of training examples and learn the probability \n",
      "distribution that generated them. Generative Adversarial \n",
      "Networks (GANs) are then able to generate more examples \n",
      "from the estimated probability distribution. Generative \n",
      "models based on deep learning are common, but GANs \n",
      "are among the most successful generative models (espe-\n",
      "cially in terms of their ability to generate realistic high-\n",
      "resolution images). GANs have been successfully applied \n",
      "to a wide variety of tasks (mostly in research settings) but \n",
      "continue to present unique challenges and research \n",
      "opportunities because they are based on game theory \n",
      "while most other approaches to generative modeling are \n",
      "based on optimization.\n",
      "1. INTRODUCTION\n",
      "Most current approaches to developing artificial intelli-\n",
      "gence are based primarily on machine learning. The most \n",
      "widely used and successful form of machine learning to date \n",
      "is supervised learning. Supervised learning algorithms are \n",
      "given a dataset of pairs of example inputs and example out-\n",
      "puts. They learn to associate each input with each output \n",
      "and thus learning a mapping from input to output exam-\n",
      "ples. The input examples are typically complicated data \n",
      "objects like images, natural language sentences, or audio \n",
      "waveforms, while the output examples are often relatively \n",
      "simple. The most common kind of supervised learning is \n",
      "classification, where the output is just an integer code iden-\n",
      "tifying a specific category (a photo might be recognized as \n",
      "coming from category 0 containing cats, or category 1 con-\n",
      "taining dogs, etc.).\n",
      "Supervised learning is often able to achieve greater than \n",
      "human accuracy after the training process is complete, and \n",
      "thus has been integrated into many products and services. \n",
      "Unfortunately, the learning process itself still falls far short \n",
      "of human abilities. Supervised learning by definition relies \n",
      "on a human supervisor to provide an output example for \n",
      "each input example. Worse, existing approaches to super-\n",
      "vised learning often require millions of training examples to \n",
      "exceed human performance, when a human might be able \n",
      "to learn to perform the task acceptably from a very small \n",
      "number of examples.\n",
      "In order to reduce both the amount of human supervi-\n",
      "sion required for learning and the number of examples \n",
      "required for learning, many researchers today study \n",
      "unsupervised learning, often using generative models. In \n",
      "this overview paper, we describe one particular approach \n",
      "to unsupervised learning via generative modeling called \n",
      "generative adversarial networks. We briefly review The original version of this paper is entitled “Generative \n",
      "Adversarial Networks” and was published in Advances in \n",
      "Neural Information Processing Systems 27 (NIPS 2014).applications of GANs and identify core research problems \n",
      "related to convergence in games necessary to make GANs a \n",
      "reliable technology.\n",
      "2. GENERATIVE MODELING\n",
      "The goal of supervised learning is relatively straightforward \n",
      "to specify, and all supervised learning algorithms have \n",
      "essentially the same goal: learn to accurately associate new \n",
      "input examples with the correct outputs. For instance, an \n",
      "object recognition algorithm may associate a photo of a dog \n",
      "with some kind of DOG category identifier.\n",
      "Unsupervised learning is a less clearly defined branch of \n",
      "machine learning, with many different unsupervised learn-\n",
      "ing algorithms pursuing many different goals. Broadly \n",
      "speaking, the goal of unsupervised learning is to learn some-\n",
      "thing useful by examining a dataset containing unlabeled \n",
      "input examples. Clustering and dimensionality reduction \n",
      "are common examples of unsupervised learning.\n",
      "Another approach to unsupervised learning is generative \n",
      "modeling. In generative modeling, training examples x are \n",
      "drawn from an unknown distribution pdata(x). The goal of a \n",
      "generative modeling algorithm is to learn a pmodel(x) that \n",
      "approximates pdata(x) as closely as possible.\n",
      "A straightforward way to learn an approximation of pdata is \n",
      "to explicitly write a function pmodel(x; θ) controlled by param-\n",
      "eters θ and search for the value of the parameters that makes \n",
      "pdata and pmodel as similar as possible. In particular, the most \n",
      "popular approach to generative modeling is probably maxi-\n",
      "mum likelihood estimation, consisting of minimizing the \n",
      "Kullback-Leibler divergence between pdata and pmodel. The \n",
      "common approach of estimating the mean parameter of a \n",
      "Gaussian distribution by taking the mean of a set of observa-\n",
      "tions is one example of maximum likelihood estimation. \n",
      "This approach based on explicit density functions is illus-\n",
      "trated in Figure 1.\n",
      "Explicit density modeling has worked well for traditional \n",
      "statistics, using simple functional forms of probability dis-\n",
      "tributions, usually applied to small numbers of variables. \n",
      "More recently, with the rise of machine learning in general \n",
      "and deep learning in particular, researchers have become \n",
      "interested in learning models that make use of relatively \n",
      "complicated functional forms. When a deep neural net-\n",
      "work is used to generate data, the corresponding density \n",
      "function may be computationally intractable. \n",
      "Traditionally, there have been two dominant approaches \n",
      "to confronting this intractability problem: (1) carefully \n",
      "design the model to have a tractable density function \n",
      "(e.g., Frey11) and (2) design a learning algorithm based on \n"
     ]
    }
   ],
   "source": [
    "page = reader.pages[0]\n",
    "\n",
    "parts = []\n",
    "\n",
    "\n",
    "def visitor_body(text, cm, tm, fontDict, fontSize):\n",
    "    y = tm[5]\n",
    "    if y > 30 and y < 670:\n",
    "        parts.append(text)\n",
    "\n",
    "\n",
    "page.extract_text(visitor_text=visitor_body)\n",
    "text_body = \"\".join(parts)\n",
    "\n",
    "print(text_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3ce7a0",
   "metadata": {},
   "source": [
    "### 2.6.3 Extracting Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ce00c",
   "metadata": {},
   "source": [
    "Every page of a PDF document can contain an arbitrary number of images. The names of the files may not be unique.\n",
    "The following piece of code extracts the images of the second page of the pdf file and saves them in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c73ff372",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = reader.pages[1]\n",
    "count = 0\n",
    "\n",
    "for image_file_object in page.images:\n",
    "    with open(str(count) + image_file_object.name, \"wb\") as fp:\n",
    "        fp.write(image_file_object.data)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed3dbad",
   "metadata": {},
   "source": [
    "### 2.6.4 Reading PDF Annotations\n",
    "\n",
    "We can also access the annotations that may be available in our pdf files. In the *GAN.pdf* file, We have 3 tentative annotations. The first page contains a sticky note containing some text, together with some highlighted text which also contains some text. There is another sticky note in the second page. We can access these texts like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44efd3ce",
   "metadata": {},
   "source": [
    "#### Sticky notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eb2b3a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the note in the first page.\n",
      "This is the note in the second page.\n"
     ]
    }
   ],
   "source": [
    "for page in reader.pages:\n",
    "    if \"/Annots\" in page:\n",
    "        for annot in page[\"/Annots\"]:\n",
    "            subtype = annot.get_object()[\"/Subtype\"]\n",
    "            if subtype == \"/Text\":\n",
    "                print(annot.get_object()[\"/Contents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb1782b",
   "metadata": {},
   "source": [
    "#### Highlighted text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f98d2d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the note on the highlighted text in page one.\n"
     ]
    }
   ],
   "source": [
    "for page in reader.pages:\n",
    "    if \"/Annots\" in page:\n",
    "        for annot in page[\"/Annots\"]:\n",
    "            subtype = annot.get_object()[\"/Subtype\"]\n",
    "            if subtype == \"/Highlight\":\n",
    "                print(annot.get_object()[\"/Contents\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
